{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__This notebook__ showcases how to infer trained students obtained using distill_waveglow.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import librosa\n",
    "from scipy.io import wavfile\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from models import defaults\n",
    "from mel2samp import Mel2Samp, load_wav_to_torch\n",
    "from denoiser import StudentDenoiser, TeacherDenoiser\n",
    "\n",
    "np.random.seed(1337)\n",
    "torch.manual_seed(1337)\n",
    "torch.cuda.manual_seed_all(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_wav(audio, path):\n",
    "    wavfile.write(\n",
    "        \"tmp.wav\", defaults.SAMPLING_RATE, \n",
    "        (np.clip(audio, -1, 1) * 32767).astype(np.int16)\n",
    "    )\n",
    "    !sox \"tmp.wav\" {path} norm -1\n",
    "    !rm \"tmp.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_kwargs = dict(\n",
    "    split='test',\n",
    "    segment_length=None,\n",
    "    filter_length=defaults.STFT_FILTER_LENGTH,\n",
    "    hop_length=defaults.STFT_HOP_LENGTH,\n",
    "    win_length=defaults.STFT_WIN_LENGTH,\n",
    "    sampling_rate=defaults.SAMPLING_RATE,\n",
    "    mel_fmin=defaults.MEL_FMIN,\n",
    "    mel_fmax=defaults.MEL_FMAX\n",
    ")\n",
    "test_dataset = Mel2Samp(\"../data/wavs\", **dataset_kwargs)\n",
    "\n",
    "test_loader_kwargs = dict(\n",
    "    num_workers=1, shuffle=False,\n",
    "    batch_size=1, pin_memory=False\n",
    ")\n",
    "test_loader = data.DataLoader(test_dataset, **test_loader_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../pretrained_models'\n",
    "sample_path = '../samples'\n",
    "                            \n",
    "sigma = 1.0\n",
    "device = 'cuda'\n",
    "dtype = torch.float16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.waveglow_teacher import WaveGlowTeacher\n",
    "teacher_path = os.path.join(model_path, 'wg_teacher_ch256_wn12.pth')\n",
    "teacher = WaveGlowTeacher.load(teacher_path, fp16=(dtype==torch.float16)).train(False).to(device)\n",
    "teacher_denoiser = TeacherDenoiser(teacher, mode='zeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create student models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from denoiser import StudentDenoiser\n",
    "from models.students import WaveNetStudent, WideFlowStudent, FlowStudent, AffineStudent\n",
    "\n",
    "\n",
    "def create_student(model_path, ch=96, wn=4, student_arch='wg'):\n",
    "    if student_arch == 'wg':\n",
    "        student = WaveNetStudent(in_channels=8, mel_channels=640, hid_channels=ch, n_wavenets=wn,\n",
    "                          wavenet_layers=8, kernel_size=3).to(device).train(True)\n",
    "    elif student_arch == 'flow':\n",
    "        student = FlowStudent(in_channels=8, mel_channels=640, hid_channels=ch, n_wavenets=wn,\n",
    "                              wavenet_layers=8, kernel_size=3).to(device).train(True)\n",
    "    elif student_arch == 'wide_flow':\n",
    "        student = WideFlowStudent(in_channels=8, mel_channels=640, hid_channels=ch, n_wavenets=wn,\n",
    "                              wavenet_layers=8, kernel_size=3).to(device).train(True)\n",
    "    elif student_arch == 'affine':\n",
    "        student = AffineStudent(in_channels=8, mel_channels=640, hid_channels=ch, n_wavenets=wn,\n",
    "                                wavenet_layers=8, kernel_size=3).to(device).train(True)\n",
    "    \n",
    "    ckpt_path = os.path.join(model_path, f'{student_arch}_student_ch{ch}_wn{wn}.pth')\n",
    "    checkpoint = torch.load(ckpt_path)\n",
    "    student.load_state_dict(checkpoint['state_dict'])\n",
    "    \n",
    "    def remove(conv_list):\n",
    "        new_conv_list = nn.ModuleList()\n",
    "        for old_conv in conv_list:\n",
    "            old_conv = nn.utils.remove_weight_norm(old_conv)\n",
    "            new_conv_list.append(old_conv)\n",
    "        return new_conv_list\n",
    "\n",
    "    wavenets = student.WN if hasattr(student, \"WN\") else student.wavenets\n",
    "    for wn in wavenets:\n",
    "        wn.start = nn.utils.remove_weight_norm(wn.start)\n",
    "        wn.in_layers = remove(wn.in_layers)\n",
    "        wn.cond_layers = nn.utils.remove_weight_norm(wn.cond_layer)\n",
    "        wn.res_skip_layers = remove(wn.res_skip_layers)\n",
    "    return student.train(False).to(dtype).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students = {}\n",
    "students['wg_ch96_wn2'] = create_student(model_path, ch=96, wn=2)\n",
    "students['wg_ch96_wn4'] = create_student(model_path, ch=96, wn=4)\n",
    "students['wg_ch128_wn4'] = create_student(model_path, ch=128, wn=4)\n",
    "students['flow_ch96_wn4'] = create_student(model_path, ch=96, wn=4, student_arch='flow')\n",
    "students['wide_flow_sh96_wn4'] = create_student(model_path, ch=96, wn=4, student_arch='wide_flow')\n",
    "students['affine_sh96_wn4'] = create_student(model_path, ch=96, wn=4, student_arch='affine')\n",
    "\n",
    "student_denoisers = {}\n",
    "for key, student in students.items():\n",
    "    student_denoisers[key] = StudentDenoiser(student, teacher, mode='zeros')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "result_path = os.path.join(sample_path, 'release')\n",
    "!rm -rf {result_path}\n",
    "!mkdir -p {result_path}\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for sample_i, (mel, wav) in enumerate(tqdm(test_loader)):\n",
    "    sample_path = test_dataset.audio_files[sample_i]\n",
    "    sample_id = str(sample_path).split('/')[-1].split('.')[0]\n",
    "    mel = mel.to(dtype).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        ### Teacher ###\n",
    "        inputs = teacher.sample_inputs_for(mel, sigma=sigma)\n",
    "        teacher_prediction = teacher(*inputs)\n",
    "        while (teacher_prediction < -1).any() or (teacher_prediction > 1).any():\n",
    "            inputs = teacher.sample_inputs_for(mel, sigma=sigma)\n",
    "            teacher_prediction = teacher(*inputs)\n",
    "\n",
    "        teacher_prediction = teacher_denoiser(teacher_prediction, strength=0.004)\n",
    "        teacher_audio = teacher_prediction.reshape(-1).clamp(-1, 1).data.cpu().float().numpy()\n",
    "\n",
    "        ### Students ###\n",
    "        student_mel = inputs[0]\n",
    "        student_audios = {}\n",
    "        for key in students.keys():\n",
    "            student_input = torch.cat(inputs[1:], dim=1)\n",
    "            student_prediction = students[key](student_input, student_mel).permute(0, 2, 1).flatten(1)\n",
    "            student_prediction = student_denoisers[key](student_prediction, strength=0.004) \n",
    "            student_audios[key] = student_prediction.reshape(-1).clamp(-1, 1).data.cpu().float().numpy()\n",
    "\n",
    "    path = os.path.join(result_path, 'teacher')\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    save_wav(teacher_audio, os.path.join(path, f\"{sample_id}.wav\"))\n",
    "\n",
    "    for i, (key, student_audio) in enumerate(student_audios.items()):        \n",
    "        path = os.path.join(result_path, f'{key}')\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        save_wav(student_audio, os.path.join(path, f\"{sample_id}.wav\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimate inference speed (MHz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_teacher_inference_speed(model, denoiser, repetitions=50):\n",
    "    assert not model.training\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    timings=np.zeros((repetitions,1))\n",
    "    \n",
    "    mel = test_dataset[0][0]\n",
    "    inputs = model.sample_inputs_for(mel.unsqueeze(0).half().cuda())\n",
    "    inputs = [input.repeat(32, 1, 2) for input in inputs]\n",
    "    \n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        output = denoiser(model(*inputs))\n",
    "    num_samples = np.prod(output.shape)\n",
    "\n",
    "    # MEASURE PERFORMANCE\n",
    "    for rep in tqdm(range(repetitions)):\n",
    "        starter.record()\n",
    "        denoiser(model(*inputs))\n",
    "        ender.record()\n",
    "        # WAIT FOR GPU SYNC\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings[rep] = curr_time\n",
    "    mean_syn = np.sum(timings) / repetitions\n",
    "    std_syn = np.std(timings)\n",
    "    mhz = num_samples / mean_syn / 1000\n",
    "    return mhz\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_student_inference_speed(model, denoiser, repetitions=50):\n",
    "    assert not model.training\n",
    "    starter, ender = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    timings=np.zeros((repetitions,1))\n",
    "    \n",
    "    mel = test_dataset[0][0]\n",
    "    inputs = teacher.sample_inputs_for(mel.unsqueeze(0).half().cuda())\n",
    "    inputs = [input.repeat(32, 1, 2) for input in inputs]\n",
    "    student_mel = inputs[0]\n",
    "    student_input = torch.cat(inputs[1:], dim=1)\n",
    "    \n",
    "    #GPU-WARM-UP\n",
    "    for _ in range(10):\n",
    "        output = denoiser(model(student_input, student_mel).permute(0, 2, 1).flatten(1))\n",
    "    num_samples = np.prod(output.shape)\n",
    "    \n",
    "    # MEASURE PERFORMANCE\n",
    "    for rep in tqdm(range(repetitions)):\n",
    "        starter.record()\n",
    "        denoiser(model(student_input, student_mel).permute(0, 2, 1).flatten(1))\n",
    "        ender.record()\n",
    "        # WAIT FOR GPU SYNC\n",
    "        torch.cuda.synchronize()\n",
    "        curr_time = starter.elapsed_time(ender)\n",
    "        timings[rep] = curr_time\n",
    "    mean_syn = np.sum(timings) / repetitions\n",
    "    std_syn = np.std(timings)\n",
    "    mhz = num_samples / mean_syn / 1000\n",
    "    return mhz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mhz = get_teacher_inference_speed(teacher, teacher_denoiser)\n",
    "print(f\"Teacher MHz: {mhz}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, student in students.items():\n",
    "    mhz = get_student_inference_speed(student, student_denoisers[key])\n",
    "    print(f\"{key} MHz: {mhz}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
